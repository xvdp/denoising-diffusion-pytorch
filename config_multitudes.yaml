## example train file
data: "/home/z/data/Self/Multitudes"

train:
  ema_decay: 0.995
  train_batch_size: 48  # fits ~24G GPU no fp16
  train_lr: 2e-5        # TODO implement schedule
  train_num_steps: 100000
  gradient_accumulate_every: 2
  fp16: False           # on titanrtx, 2x slower
  step_start_ema: 2000
  update_ema_every: 10
  save_and_sample_every: 1000
  results_folder: './results_multitudes'  # training floder
  milestone: 'last' # load last milestone | or number '15000'

diffusion:
  image_size: 128
  timesteps: 1000
  loss_type: 'l1'
  betas:

model:
  dim: 64
  out_dim:
  dim_mults: [1, 2, 4, 8]
  channels: 3
  with_time_emb: True
